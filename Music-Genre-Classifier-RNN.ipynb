{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP97LxtF2s0OVJ2RAXMbnXo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Music-Genre-Classifier RNN\n","Kaito Minami"],"metadata":{"id":"Apq84fiWwQIm"}},{"cell_type":"code","execution_count":54,"metadata":{"id":"ElPCOKzzedOW","executionInfo":{"status":"ok","timestamp":1730067367697,"user_tz":240,"elapsed":235,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"outputs":[],"source":["import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout\n","from keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","import librosa\n","import librosa.display\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import os\n","from sklearn.preprocessing import StandardScaler\n","import audioread\n","from sklearn.preprocessing import StandardScaler\n","# from pydub import AudioSegment\n"]},{"cell_type":"markdown","source":["## 1. Data Processing"],"metadata":{"id":"KMNZyAb1wKU4"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSmsQU9QvXKm","executionInfo":{"status":"ok","timestamp":1730067372324,"user_tz":240,"elapsed":4411,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}},"outputId":"90dcc17a-1b14-41e5-9cc7-33b1c2811d02"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Load the datasets\n","file_30_sec = '/content/drive/MyDrive/Colab Notebooks/GTZAN/features_30_sec.csv'\n","file_3_sec = '/content/drive/MyDrive/Colab Notebooks/GTZAN/features_3_sec.csv'\n","\n","df_30_sec = pd.read_csv(file_30_sec)\n","df_3_sec = pd.read_csv(file_3_sec)"],"metadata":{"id":"ju4_S1RJvzdV","executionInfo":{"status":"ok","timestamp":1730067372325,"user_tz":240,"elapsed":20,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["# Function to extract Mel spectrogram features\n","def extract_mel_spectrogram(file_path, sr=22050, n_mels=128):\n","    try:\n","        # Load audio file\n","        y, sr = librosa.load(file_path, sr=sr)\n","        # Extract Mel spectrogram\n","        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n","        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n","        mel_spectrogram_flattened = mel_spectrogram_db.flatten()  # Flatten for use in ML models\n","    except (FileNotFoundError, librosa.util.exceptions.LibrosaError, audioread.NoBackendError):\n","        print(f\"Audio file {file_path} not found or cannot be processed. Using CSV features instead.\")\n","        mel_spectrogram_flattened = None\n","    return mel_spectrogram_flattened\n","\n","# Splitting the dataset into training, validation, and test sets\n","def split_data(df, test_size=0.2, val_size=0.2):\n","    train_val, test = train_test_split(df, test_size=test_size, stratify=df['label'], random_state=42)\n","    train, val = train_test_split(train_val, test_size=val_size, stratify=train_val['label'], random_state=42)\n","    return train, val, test\n","\n","# Function to process the entire dataset and extract features\n","def process_dataset(df, audio_directory, feature_type='mel'):\n","    features = []\n","    labels = []\n","    for idx, row in df.iterrows():\n","        file_path = os.path.join(audio_directory, row['label'], row['filename'])\n","        if feature_type == 'mel':\n","            feature_vector = extract_mel_spectrogram(file_path)\n","        elif feature_type == 'wavelet':\n","            feature_vector = extract_wavelet_features(file_path)\n","        elif feature_type == 'chroma':\n","            feature_vector = extract_chroma_features(file_path)\n","        else:\n","            raise ValueError(\"Invalid feature type. Choose from 'mel', 'wavelet', 'chroma'.\")\n","\n","        # If audio features cannot be extracted, use CSV features\n","        if feature_vector is None:\n","            feature_vector = row.drop(['label']).filter(regex='^(?!filename)').values.astype(np.float32)\n","        features.append(feature_vector)\n","        labels.append(row['label'])\n","\n","    # Ensure all feature vectors have the same length by padding or truncating\n","    max_length = max(len(f) for f in features)\n","    features = np.array([np.pad(f, (0, max_length - len(f)), 'constant') if len(f) < max_length else f[:max_length] for f in features])\n","    return features, np.array(labels)"],"metadata":{"id":"y8zR9tITv-2B","executionInfo":{"status":"ok","timestamp":1730067372325,"user_tz":240,"elapsed":18,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# Standardizing dataset before splitting\n","scaler = StandardScaler()\n","df_30_sec_numeric = df_30_sec.select_dtypes(include=['float64', 'int64']).copy()\n","df_30_sec[df_30_sec_numeric.columns] = scaler.fit_transform(df_30_sec_numeric)\n","\n","df_3_sec_numeric = df_3_sec.select_dtypes(include=['float64', 'int64']).copy()\n","df_3_sec[df_3_sec_numeric.columns] = scaler.fit_transform(df_3_sec_numeric)\n","\n","# Splitting the dataset for 30-sec\n","train_df_30_sec, val_df_30_sec, test_df_30_sec = split_data(df_30_sec)\n","\n","# Extract and process features for 30-sec dataset\n","audio_directory = '/content/drive/MyDrive/Colab Notebooks/GTZAN/genres_original'\n","\n","# Mel Spectrogram Features\n","train_mel_features, train_mel_labels = process_dataset(train_df_30_sec, audio_directory, feature_type='mel')\n","val_mel_features, val_mel_labels = process_dataset(val_df_30_sec, audio_directory, feature_type='mel')\n","test_mel_features, test_mel_labels = process_dataset(test_df_30_sec, audio_directory, feature_type='mel')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GF8x7JFYv_2o","executionInfo":{"status":"ok","timestamp":1730067436341,"user_tz":240,"elapsed":64032,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}},"outputId":"9bdaebca-28ad-4975-df7e-5169f81ae592"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-57-fff06d422e59>:5: UserWarning: PySoundFile failed. Trying audioread instead.\n","  y, sr = librosa.load(file_path, sr=sr)\n","/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]},{"output_type":"stream","name":"stdout","text":["Audio file /content/drive/MyDrive/Colab Notebooks/GTZAN/genres_original/jazz/jazz.00054.wav not found or cannot be processed. Using CSV features instead.\n"]}]},{"cell_type":"code","source":["train_mel_features = train_mel_features.reshape(train_mel_features.shape[0], train_mel_features.shape[1])"],"metadata":{"id":"jQyDy0by8ghj","executionInfo":{"status":"ok","timestamp":1730067836740,"user_tz":240,"elapsed":256,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":["## 2. LSTM model"],"metadata":{"id":"vGFjzrVNwX34"}},{"cell_type":"code","source":["def one_hot(genre_strings):\n","    genre_list = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]\n","\n","    y_one_hot = np.zeros((genre_strings.shape[0], len(genre_list)))\n","    for i, genre_string in enumerate(genre_strings):\n","        index = genre_list.index(genre_string)\n","        y_one_hot[i, index] = 1\n","    return y_one_hot"],"metadata":{"id":"pI58QjTj6FfO","executionInfo":{"status":"ok","timestamp":1730067436344,"user_tz":240,"elapsed":37,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# Model building\n","model = Sequential()\n","input_shape = (train_mel_features.shape[0], train_mel_features.shape[1])\n","\n","model.add(LSTM(units=128, dropout=0.05, recurrent_dropout=0.35, return_sequences=True, input_shape=input_shape))\n","model.add(LSTM(units=32,  dropout=0.05, recurrent_dropout=0.35, return_sequences=False))\n","model.add(Dense(units=len(np.unique(train_mel_labels)), activation=\"softmax\"))\n","\n","# Model compiling\n","opt = Adam()\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","model.summary()\n","\n","# Model training\n","batch_size = 35  # num of training examples per minibatch\n","num_epochs = 400\n","\n","print(train_mel_features.shape, one_hot(train_mel_labels).shape)\n","\n","history = model.fit(\n","    train_mel_features,\n","    one_hot(train_mel_labels),\n","    batch_size=batch_size,\n","    epochs=num_epochs,\n","    validation_data=(val_mel_features, one_hot(val_mel_labels))\n",")\n","\n","# Testing\n","score, accuracy = model.evaluate(\n","    test_mel_features, one_hot(test_mel_labels), batch_size=batch_size, verbose=1\n",")\n","print(\"Test loss:  \", score)\n","print(\"Test accuracy:  \", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":799},"id":"zlgx3CYgldIl","executionInfo":{"status":"error","timestamp":1730067903831,"user_tz":240,"elapsed":1895,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}},"outputId":"bfe2b76c-f657-4b08-f719-1da9b41784bb"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_25\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_25\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm_41 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │      \u001b[38;5;34m86,573,568\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm_42 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m20,608\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">86,573,568</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m86,594,506\u001b[0m (330.33 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,594,506</span> (330.33 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m86,594,506\u001b[0m (330.33 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,594,506</span> (330.33 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(640, 168960) (640, 10)\n","Epoch 1/400\n"]},{"output_type":"error","ename":"ValueError","evalue":"Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 168960), dtype=float32). Expected shape (None, 640, 168960), but input has incompatible shape (None, 168960)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 168960), dtype=float32)\n  • training=True\n  • mask=None","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-ea387061818c>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mel_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mel_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_mel_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mel_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m_adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0madjusted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;34mf\"Invalid input shape for input {x}. Expected shape \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;34mf\"{ref_shape}, but input has incompatible shape {x.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 168960), dtype=float32). Expected shape (None, 640, 168960), but input has incompatible shape (None, 168960)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 168960), dtype=float32)\n  • training=True\n  • mask=None"]}]},{"cell_type":"code","source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'])\n","plt.show()"],"metadata":{"id":"0ylcJg8jmbgB","executionInfo":{"status":"aborted","timestamp":1730067437596,"user_tz":240,"elapsed":19,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"execution_count":null,"outputs":[]}]}