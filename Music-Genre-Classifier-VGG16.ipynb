{"cells":[{"cell_type":"code","execution_count":1,"id":"e1e70d0c","metadata":{"id":"e1e70d0c","executionInfo":{"status":"ok","timestamp":1732140410323,"user_tz":300,"elapsed":27692,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b6162934-3843-4717-dda2-cf8fd8845a85"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: Pydub\n","Successfully installed Pydub-0.25.1\n","Collecting PyWavelets\n","  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from PyWavelets) (1.26.4)\n","Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyWavelets\n","Successfully installed PyWavelets-1.7.0\n"]}],"source":["!pip install Pydub\n","!pip install PyWavelets\n","\n","\n","import numpy as np\n","import librosa\n","import librosa.display\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import pywt\n","import pandas as pd\n","import os\n","from sklearn.preprocessing import StandardScaler\n","import audioread\n","from pydub import AudioSegment\n","import tensorflow as tf\n","# from tensorflow.keras import layers, models\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D , Flatten, Reshape, Input"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_iyNvV1qrVx","executionInfo":{"status":"ok","timestamp":1732140439616,"user_tz":300,"elapsed":29312,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}},"outputId":"b7964c73-fe9e-4a7c-a25c-2fca156b97c3"},"id":"X_iyNvV1qrVx","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"id":"b93cf69e","metadata":{"id":"b93cf69e","executionInfo":{"status":"ok","timestamp":1732140444625,"user_tz":300,"elapsed":5022,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"outputs":[],"source":["# Load the datasets\n","#file_30_sec = 'data/GTZAN/features_30_sec.csv'\n","#file_3_sec = 'data/GTZAN/features_3_sec.csv'\n","\n","file_30_sec = '/content/drive/MyDrive/Colab Notebooks/GTZAN/features_30_sec.csv'\n","file_3_sec = '/content/drive/MyDrive/Colab Notebooks/GTZAN/features_3_sec.csv'\n","audio_directory = '/content/drive/MyDrive/Colab Notebooks/GTZAN/genres_original'\n","\n","df_30_sec = pd.read_csv(file_30_sec)\n","df_3_sec = pd.read_csv(file_3_sec)"]},{"cell_type":"code","execution_count":4,"id":"b0ec6226","metadata":{"id":"b0ec6226","executionInfo":{"status":"ok","timestamp":1732140444626,"user_tz":300,"elapsed":13,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"outputs":[],"source":["# Function to extract spectrograms and wavelet features\n","def extract_features(file_path, sr=22050, n_mels=128, wavelet='db1'):\n","    try:\n","        # Load audio file\n","        y, sr = librosa.load(file_path, sr=sr)\n","        # Extract Mel spectrogram\n","        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n","        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n","        mel_spectrogram_flattened = mel_spectrogram_db.flatten()  # Flatten for use in ML models\n","\n","        # Extract wavelet features\n","        coeffs = pywt.wavedec(y, wavelet, level=5)\n","        wavelet_features = np.concatenate([np.array(c).flatten() for c in coeffs])\n","\n","        # Extract chroma features\n","        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n","        chroma_features_flattened = chroma_stft.flatten()  # Flatten for use in ML models\n","\n","        # Combine all features into a single feature vector\n","        combined_features = np.concatenate((mel_spectrogram_flattened, wavelet_features, chroma_features_flattened), axis=0)\n","    except (FileNotFoundError, librosa.util.exceptions.LibrosaError, audioread.NoBackendError):\n","        # If audio file is not found or cannot be loaded, use features from CSV instead\n","        print(f\"Audio file {file_path} not found or cannot be processed. Using CSV features instead.\")\n","        combined_features = None\n","\n","    return combined_features\n","\n","# Splitting the dataset into training, validation, and test sets\n","def split_data(df, test_size=0.2, val_size=0.2):\n","    train_val, test = train_test_split(df, test_size=test_size, stratify=df['label'], random_state=42)\n","    train, val = train_test_split(train_val, test_size=val_size, stratify=train_val['label'], random_state=42)\n","    return train, val, test\n","\n","# Function to process the entire dataset and extract features\n","def process_dataset(df, audio_directory):\n","    features = []\n","    labels = []\n","    for idx, row in df.iterrows():\n","        file_path = os.path.join(audio_directory, row['label'], row['filename'])\n","        feature_vector = extract_features(file_path)\n","        # If audio features cannot be extracted, use CSV features\n","        if feature_vector is None:\n","            feature_vector = row.drop(['label']).filter(regex='^(?!filename)').values.astype(np.float32)\n","        features.append(feature_vector)\n","        labels.append(row['label'])\n","    # Ensure all feature vectors have the same length by padding or truncating\n","    max_length = max(len(f) for f in features)\n","    features = np.array([np.pad(f, (0, max_length - len(f)), 'constant') if len(f) < max_length else f[:max_length] for f in features])\n","    return features, np.array(labels)"]},{"cell_type":"code","source":["# Standardizing dataset before splitting\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","df_30_sec_numeric = df_30_sec.select_dtypes(include=['float64', 'int64']).copy()\n","df_30_sec[df_30_sec_numeric.columns] = scaler.fit_transform(df_30_sec_numeric)\n","\n","df_3_sec_numeric = df_3_sec.select_dtypes(include=['float64', 'int64']).copy()\n","df_3_sec[df_3_sec_numeric.columns] = scaler.fit_transform(df_3_sec_numeric)"],"metadata":{"id":"HY-8hkdK6bOG","executionInfo":{"status":"ok","timestamp":1732140444944,"user_tz":300,"elapsed":329,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"id":"HY-8hkdK6bOG","execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"id":"825122af","metadata":{"id":"825122af","outputId":"56759645-558d-4018-ea56-80bced19981d","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1732141382927,"user_tz":300,"elapsed":937990,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-1192b0c4e0fd>:5: UserWarning: PySoundFile failed. Trying audioread instead.\n","  y, sr = librosa.load(file_path, sr=sr)\n","/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]},{"output_type":"stream","name":"stdout","text":["Audio file /content/drive/MyDrive/Colab Notebooks/GTZAN/genres_original/jazz/jazz.00054.wav not found or cannot be processed. Using CSV features instead.\n"]}],"source":["# Splitting the dataset for 30-sec\n","train_df_30s, val_df_30s, test_df_30s = split_data(df_30_sec)\n","\n","# Extract and process features for 30-sec dataset\n","#audio_directory = 'data/GTZAN/genres_original'\n","\n","# Extract and process features for 30-sec dataset\n","#audio_directory = 'data/GTZAN/genres_original'\n","\n","# Combined Features for 30-sec\n","train_features_30s, train_labels_30s = process_dataset(train_df_30s, audio_directory)\n","val_features_30s, val_labels_30s = process_dataset(val_df_30s, audio_directory)\n","test_features_30s, test_labels_30s = process_dataset(test_df_30s, audio_directory)"]},{"cell_type":"code","execution_count":7,"id":"390ae947","metadata":{"id":"390ae947","outputId":"26f91eb9-133a-4c1d-d1aa-1a22f6b9a61b","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1GtJpnunKj1k2s6F4DQiQv3p90acUEwrA"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1732141408445,"user_tz":300,"elapsed":25537,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Splitting the dataset for 3-sec\n","train_df_3s, val_df_3s, test_df_3s = split_data(df_3_sec)\n","\n","# Combined Features for 3-sec\n","train_features_3s, train_labels_3s = process_dataset(train_df_3s, audio_directory)\n","val_features_3s, val_labels_3s = process_dataset(val_df_3s, audio_directory)\n","test_features_3s, test_labels_3s = process_dataset(test_df_3s, audio_directory)"]},{"cell_type":"code","source":["# CNN Model Implementation\n","# Function to build a CNN model\n","\n","\"\"\"\n","def build_cnn_model(input_shape, num_classes):\n","    model = models.Sequential()\n","    model.add(layers.Input(shape=(input_shape,)))\n","    model.add(layers.Dense(256, activation='relu'))  # Increased number of units\n","    model.add(layers.Reshape((32, 8, 1)))  # Adjusted reshape to match input dimensions\n","    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))  # Increased filters\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))  # Added more layers\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))  # Added deeper layers\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(64, activation='relu'))  # Increased number of units\n","    model.add(layers.Dropout(0.5))  # Added Dropout layer to prevent overfitting\n","    model.add(layers.Dense(num_classes, activation='softmax'))\n","\n","    model.compile(optimizer='adam',\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n","\"\"\"\n","\n","# VGG16 Model Implementation\n","# Function to build a VGG16 model\n","\n","def build_vgg16_model(input_shape, num_classes):\n","    # Create an object for training and testing\n","    model = Sequential()\n","    model.add(Input(shape=input_shape))\n","    # model.add(Reshape((32, 8, 1)))  # Adjusted reshape to match input dimensions\n","    model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n","    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\")) # input_shape\n","    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n","    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n","    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n","    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n","    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n","\n","    # Initialize the model\n","    model.add(Flatten())\n","    model.add(Dense(units=4096,activation=\"relu\"))\n","    model.add(Dense(units=4096,activation=\"relu\"))\n","    model.add(Dense(units=num_classes, activation=\"softmax\"))\n","\n","    model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n","\n","# Convert labels to numeric format\n","from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","train_labels_30s = le.fit_transform(train_labels_30s)\n","val_labels_30s = le.transform(val_labels_30s)\n","test_labels_30s = le.transform(test_labels_30s)\n","\n","train_labels_3s = le.fit_transform(train_labels_3s)\n","val_labels_3s = le.transform(val_labels_3s)\n","test_labels_3s = le.transform(test_labels_3s)\n","\n","# Callback for reducing learning rate\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)"],"metadata":{"id":"hI4sZbDCMzMP","executionInfo":{"status":"ok","timestamp":1732141408446,"user_tz":300,"elapsed":15,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"id":"hI4sZbDCMzMP","execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Combined Features CNN Model for 30-sec Features\n","print(train_features_30s.shape)\n","print(len(np.unique(train_labels_30s)))\n","combined_vgg16_model_30s = build_vgg16_model((32,8,1), len(np.unique(train_labels_30s)))\n","history_30s = combined_vgg16_model_30s.fit(train_features_30s, train_labels_30s, epochs=100, validation_data=(val_features_30s, val_labels_30s), batch_size=32, callbacks=[reduce_lr])\n","combined_predictions_30s = combined_vgg16_model_30s.predict(test_features_30s)\n","print(\"Combined Features Predictions for 30-sec Features: \", np.argmax(combined_predictions_30s, axis=1))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"9rScZQao0KIz","executionInfo":{"status":"error","timestamp":1732141410804,"user_tz":300,"elapsed":2371,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}},"outputId":"d38239a6-e232-4a0f-c893-3ac86c8e2e42","collapsed":true},"id":"9rScZQao0KIz","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["(2151520, 32, 8, 1)\n","10\n"]},{"output_type":"error","ename":"ValueError","evalue":"Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 2151520\n'y' sizes: 640\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-d16dec0557ac>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_30s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcombined_vgg16_model_30s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vgg16_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_30s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory_30s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_vgg16_model_30s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features_30s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_30s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features_30s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels_30s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcombined_predictions_30s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_vgg16_model_30s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features_30s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Combined Features Predictions for 30-sec Features: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_predictions_30s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/data_adapter_utils.py\u001b[0m in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    112\u001b[0m             )\n\u001b[1;32m    113\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"'{label}' sizes: {sizes}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 2151520\n'y' sizes: 640\n"]}]},{"cell_type":"code","source":["# Combined Features CNN Model for 3-sec Features\n","combined_vgg16_model_3s = build_vgg16_model((32,8,1), len(np.unique(train_labels_3s)))\n","history_3s = combined_vgg16_model_3s.fit(train_features_3s, train_labels_3s, epochs=100, validation_data=(val_features_3s, val_labels_3s), batch_size=32, callbacks=[reduce_lr])\n","combined_predictions_3s = combined_vgg16_model_3s.predict(test_features_3s)\n","print(\"Combined Features Predictions for 3-sec Features: \", np.argmax(combined_predictions_3s, axis=1))"],"metadata":{"id":"Y8epBDaI2QN7","executionInfo":{"status":"aborted","timestamp":1732141410808,"user_tz":300,"elapsed":17,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}},"collapsed":true},"id":"Y8epBDaI2QN7","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting model loss and accuracy for 30-sec and 3-sec\n","import matplotlib.pyplot as plt\n","\n","def plot_losses(hist):\n","\n","  fig, axs = plt.subplots(1,2, figsize=(12, 4))\n","  axs[0].plot(hist.history['loss'])\n","  axs[0].plot(hist.history['val_loss'])\n","  axs[0].set_title('Model Loss')\n","  axs[0].set_ylabel('Loss')\n","  axs[0].set_xlabel('Epoch')\n","  axs[0].legend(['Train', 'Test'], loc='upper right')\n","\n","  axs[1].plot(hist.history['accuracy'])\n","  axs[1].plot(hist.history['val_accuracy'])\n","  axs[1].set_title('Model Accuracy')\n","  axs[1].set_ylabel('Accuracy')\n","  axs[1].set_xlabel('Epoch')\n","  axs[1].legend(['Train', 'Test'], loc='upper right')\n","  plt.show()\n","\n","# Plot for 30-sec model\n","plot_losses(history_30s)\n","\n","# Plot for 3-sec model\n","plot_losses(history_3s)"],"metadata":{"id":"wA6gtd65MvxG","executionInfo":{"status":"aborted","timestamp":1732141410809,"user_tz":300,"elapsed":18,"user":{"displayName":"Kaito Minami","userId":"17520602151836041630"}}},"id":"wA6gtd65MvxG","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[{"file_id":"https://github.com/kaito1122/Music-Genre-Classifier/blob/main/data_processing.ipynb","timestamp":1730058309835}],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}